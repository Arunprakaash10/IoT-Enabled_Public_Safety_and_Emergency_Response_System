{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d444a99-fa67-4981-9e7c-21d9db34a1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Is Akhash authorized? (yes/no):  no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: known_faces/Akhash/image_7.jpeg\n",
      "Processed image: known_faces/Akhash/image_0.jpeg\n",
      "Processed image: known_faces/Akhash/image_1.jpeg\n",
      "Processed image: known_faces/Akhash/image_2.jpeg\n",
      "Processed image: known_faces/Akhash/image_3.jpeg\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Is Arun authorized? (yes/no):  yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: known_faces/Arun/image34.jpeg\n",
      "Processed image: known_faces/Arun/image22.jpeg\n",
      "Processed image: known_faces/Arun/image18.jpeg\n",
      "Processed image: known_faces/Arun/image38.jpeg\n",
      "Processed image: known_faces/Arun/image14.jpeg\n",
      "Processed image: known_faces/Arun/image15.jpeg\n",
      "Processed image: known_faces/Arun/image19.jpeg\n",
      "Processed image: known_faces/Arun/image1.jpeg\n",
      "Processed image: known_faces/Arun/image23.jpeg\n",
      "Processed image: known_faces/Arun/image35.jpeg\n",
      "Processed image: known_faces/Arun/image28.jpeg\n",
      "Processed image: known_faces/Arun/image12.jpeg\n",
      "Processed image: known_faces/Arun/image32.jpeg\n",
      "Processed image: known_faces/Arun/image24.jpeg\n",
      "Processed image: known_faces/Arun/image6.jpeg\n",
      "Processed image: known_faces/Arun/image7.jpeg\n",
      "Processed image: known_faces/Arun/image25.jpeg\n",
      "Processed image: known_faces/Arun/image33.jpeg\n",
      "Processed image: known_faces/Arun/image13.jpeg\n",
      "Processed image: known_faces/Arun/image29.jpeg\n",
      "Processed image: known_faces/Arun/image10.jpeg\n",
      "Processed image: known_faces/Arun/image8.jpeg\n",
      "Processed image: known_faces/Arun/image4.jpeg\n",
      "Processed image: known_faces/Arun/image26.jpeg\n",
      "Processed image: known_faces/Arun/image30.jpeg\n",
      "Processed image: known_faces/Arun/image31.jpeg\n",
      "Processed image: known_faces/Arun/image27.jpeg\n",
      "Processed image: known_faces/Arun/image5.jpeg\n",
      "Processed image: known_faces/Arun/image9.jpeg\n",
      "Processed image: known_faces/Arun/image11.jpeg\n",
      "Processed image: known_faces/Arun/image2.jpeg\n",
      "Processed image: known_faces/Arun/image20.jpeg\n",
      "Processed image: known_faces/Arun/image36.jpeg\n",
      "Processed image: known_faces/Arun/image16.jpeg\n",
      "Processed image: known_faces/Arun/image17.jpeg\n",
      "Processed image: known_faces/Arun/image37.jpeg\n",
      "Processed image: known_faces/Arun/image21.jpeg\n",
      "Processed image: known_faces/Arun/image3.jpeg\n",
      "Training complete. Data saved to face_data.csv.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing known faces organized by person name in subdirectories\n",
    "KNOWN_FACES_DIR = \"known_faces\"\n",
    "\n",
    "# CSV file to save training data\n",
    "CSV_FILE = \"face_data.csv\"\n",
    "\n",
    "# Initialize lists for storing data\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "face_authorized_status = []\n",
    "\n",
    "# Load existing data from the CSV file, if it exists\n",
    "if os.path.exists(CSV_FILE):\n",
    "    face_data = pd.read_csv(CSV_FILE)\n",
    "else:\n",
    "    face_data = pd.DataFrame(columns=[\"Name\", \"Authorized\"])\n",
    "\n",
    "# Loop through each person in the known_faces directory\n",
    "for person_name in os.listdir(KNOWN_FACES_DIR):\n",
    "    person_dir = os.path.join(KNOWN_FACES_DIR, person_name)\n",
    "\n",
    "    # Check if it's a directory\n",
    "    if os.path.isdir(person_dir):\n",
    "        # Check if the person already exists in the CSV file\n",
    "        if person_name in face_data[\"Name\"].values:\n",
    "            print(f\"{person_name} is already in the CSV file. Retraining with new images...\")\n",
    "            face_data = face_data[face_data[\"Name\"] != person_name]  # Remove existing record to update\n",
    "        else:\n",
    "            # Prompt user for authorized/unauthorized status\n",
    "            while True:\n",
    "                status_input = input(f\"Is {person_name} authorized? (yes/no): \").strip().lower()\n",
    "                if status_input in ('yes', 'no'):\n",
    "                    is_authorized = True if status_input == 'yes' else False\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"Invalid input. Please enter 'yes' or 'no'.\")\n",
    "\n",
    "        # Process each image file in the person's directory\n",
    "        for filename in os.listdir(person_dir):\n",
    "            image_path = os.path.join(person_dir, filename)\n",
    "\n",
    "            # Check if the file is an image\n",
    "            if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                try:\n",
    "                    # Load the image file\n",
    "                    image = face_recognition.load_image_file(image_path)\n",
    "                    \n",
    "                    # Get face encodings\n",
    "                    encodings = face_recognition.face_encodings(image)\n",
    "                    \n",
    "                    # If an encoding is found, add it to our lists\n",
    "                    if encodings:\n",
    "                        print(f\"Processed image: {image_path}\")\n",
    "                        face_encodings.append(encodings[0])  # Save only one encoding per person\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {image_path}: {e}\")\n",
    "        \n",
    "        # Save the person's data (single record)\n",
    "        face_names.append(person_name)\n",
    "        face_authorized_status.append(is_authorized)\n",
    "\n",
    "# Convert the new data to a DataFrame\n",
    "new_face_data = pd.DataFrame({\n",
    "    \"Name\": face_names,\n",
    "    \"Authorized\": face_authorized_status\n",
    "})\n",
    "\n",
    "# Combine existing and new data, ensuring there are no duplicates\n",
    "updated_face_data = pd.concat([face_data, new_face_data], ignore_index=True)\n",
    "\n",
    "# Save the combined data back to the CSV file\n",
    "updated_face_data.to_csv(CSV_FILE, index=False)\n",
    "\n",
    "# Save face encodings to a NumPy file (optional, if needed later for detection)\n",
    "face_encodings = np.array(face_encodings)\n",
    "np.save(\"face_encodings.npy\", face_encodings)\n",
    "\n",
    "print(f\"Training complete. Data saved to {CSV_FILE}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f664b62c-422b-48f3-a1ca-792ed41843df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face detection started. Press 'q' to quit.\n",
      "Data saved: Unknown, Unauthorized, 2024-11-20 10:13:18\n",
      "Data saved: Unknown, Unauthorized, 2024-11-20 10:13:19\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from datetime import datetime\n",
    "\n",
    "# PostgreSQL connection details (replace with your details)\n",
    "db_config = {\n",
    "    'host': '34.47.193.205',\n",
    "    'port': '5432',\n",
    "    'database': 'hons',\n",
    "    'user': 'postgres',\n",
    "    'password': 'hons_postgres'\n",
    "}\n",
    "\n",
    "# CSV file containing known faces and authorization status\n",
    "CSV_FILE = \"face_data.csv\"\n",
    "\n",
    "# Load face data from CSV\n",
    "face_data = pd.read_csv(CSV_FILE)\n",
    "known_names = face_data[\"Name\"].values\n",
    "known_authorized_status = face_data[\"Authorized\"].values\n",
    "\n",
    "# Load face encodings from the saved numpy file\n",
    "known_face_encodings = np.load(\"face_encodings.npy\", allow_pickle=True)\n",
    "\n",
    "# Function to save detected person data to the PostgreSQL database\n",
    "def save_detection_to_db(name, authorized, timestamp):\n",
    "    try:\n",
    "        conn = psycopg2.connect(**db_config)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Insert detection record into the person_data table\n",
    "        insert_query = \"\"\"\n",
    "        INSERT INTO person_data (name, authorized, timestamp)\n",
    "        VALUES (%s, %s, %s)\n",
    "        \"\"\"\n",
    "        cursor.execute(insert_query, (name, authorized, timestamp))\n",
    "        \n",
    "        conn.commit()\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "        print(f\"Data saved: {name}, {'Authorized' if authorized else 'Unauthorized'}, {timestamp}\")\n",
    "    except Exception as e:\n",
    "        # Do not print exception, silently handle it\n",
    "        pass\n",
    "\n",
    "# Initialize the webcam\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "print(\"Face detection started. Press 'q' to quit.\")\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame from the webcam\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to capture image.\")\n",
    "        break\n",
    "    \n",
    "    # Resize the frame for faster processing\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "    rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Detect faces and compute face encodings in the current frame\n",
    "    face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "    face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "    \n",
    "    # Loop through each face found in the frame\n",
    "    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "        try:\n",
    "            # Compare the detected face with known faces\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding, tolerance=0.6)\n",
    "            name = \"Unknown\"\n",
    "            authorized = False\n",
    "            \n",
    "            # Check if there's a match\n",
    "            if True in matches:\n",
    "                first_match_index = matches.index(True)  # Get the first match index\n",
    "                \n",
    "                # Try to get the name and authorization status\n",
    "                name = known_names[first_match_index]\n",
    "                authorized = bool(known_authorized_status[first_match_index])\n",
    "            else:\n",
    "                name = \"Unknown\"\n",
    "                authorized = False\n",
    "            \n",
    "            # Scale face locations back up to the original frame size\n",
    "            top *= 4\n",
    "            right *= 4\n",
    "            bottom *= 4\n",
    "            left *= 4\n",
    "            \n",
    "            # Draw a rectangle around the face\n",
    "            color = (0, 255, 0) if authorized else (0, 0, 255)\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), color, 2)\n",
    "            \n",
    "            # Draw label with name and status\n",
    "            label = f\"{name} - {'Authorized' if authorized else 'Unauthorized'}\"\n",
    "            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), color, cv2.FILLED)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            cv2.putText(frame, label, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "            \n",
    "            # Log and save data to the database\n",
    "            timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            save_detection_to_db(name, authorized, timestamp)\n",
    "\n",
    "        except IndexError:\n",
    "            # Skip this face without printing the error\n",
    "            continue\n",
    "        except Exception:\n",
    "            # Skip any other errors silently without printing\n",
    "            continue\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow(\"Face Recognition\", frame)\n",
    "\n",
    "    # Wait for user input to quit\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close the OpenCV window\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Face recognition stopped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb2d66b-623b-4684-b2d5-5b178ec07d20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
